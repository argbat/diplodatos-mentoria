{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Curación - Relaciones Temporales.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oSkjVlG7Unj5","colab_type":"text"},"source":["# Curación - Relaciones Temporales en Textos Médicos"]},{"cell_type":"markdown","metadata":{"id":"HZYbJyDBUnj9","colab_type":"text"},"source":["### Recorrido por los datos\n","Vamos a trabajar primero explorando los datos de ejemplo que se proveen con el challenge.\n","Para eso hacemos uso de la función lift_data(), que extrae anotaciones de relaciones y las combina en una lista junto con el texto original."]},{"cell_type":"code","metadata":{"id":"eomaLrC9Unj_","colab_type":"code","colab":{}},"source":["from helpers import lift_dataset\n","# lift_dataset devuelve un iterador\n","dataset = list(lift_dataset('SampleData'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqZqwsmiUnkH","colab_type":"text"},"source":["## Tokenización\n","Tokenizamos los datos y calculamos el tamaño de vocabulario, para ello se puede usar el siguiente código ejemplo con SpaCy. (reemplazar esto con el código que hace la tokenización sobre la variable dataset del punto anterior).\n","El objetivo aquí es achicar el tamaño del vocabulario.\n","El texto en el punto anterior está en el penúltimo elemento de cada lista que comprende cada punto de datos."]},{"cell_type":"code","metadata":{"id":"ssh4ukE8UnkK","colab_type":"code","colab":{}},"source":["import spacy\n","sentence = 'Something that you could compute is something computable'\n","spacy_nlp = spacy.load('en_core_web_sm')\n","doc = spacy_nlp(sentence)\n","tokens = [token.text for token in doc]\n","tokens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-csP3SZUnkT","colab_type":"code","colab":{}},"source":["# imprimimos el tamaño del vocabulario\n","len(set(tokens))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"doRhZqSNUnka","colab_type":"text"},"source":["## Lematización\n","Seguimos usando SpaCy, esta vez para obtener lemas. "]},{"cell_type":"code","metadata":{"id":"MWovwWnyUnkb","colab_type":"code","colab":{}},"source":["for word in doc:  \n","    print(word.text,  word.lemma_)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kh4DZD7NUnkg","colab_type":"text"},"source":["## Sigamos normalizando\n","Algunas ideas, los números se pueden reemplazar por un token especial, _NUM_, las fechas también. \n","Utilizar el módulo de regexes de Python.\n"]},{"cell_type":"code","metadata":{"id":"rknH3E8WUnkj","colab_type":"code","colab":{}},"source":["# normalizamos números\n","\n","# normalizamos fechas\n","\n","# lower case"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-06SlheHUnkp","colab_type":"text"},"source":["## Volvemos a calcular el tamaño del vocabulario\n","El tamaño debería haberse reducido ya que hemos colapsado cosas distintas hacia los mismos tokens. \n","Más adelante vamos a ver porque esto es interesante."]},{"cell_type":"code","metadata":{"id":"QO_NscmlUnkq","colab_type":"code","colab":{}},"source":["# calculamos el tamaño del vocabulario luego de normalizar"],"execution_count":0,"outputs":[]}]}